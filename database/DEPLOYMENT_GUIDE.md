# å¾‹å¸ˆAIå·¥ä½œå°æ•°æ®åº“éƒ¨ç½²æŒ‡å—
# Lawyer AI Workstation Database Deployment Guide

## ğŸš€ å¿«é€Ÿå¼€å§‹

### å‰ææ¡ä»¶
- Node.js 18+ 
- PostgreSQL 15+ (æˆ–Supabaseè´¦æˆ·)
- Git
- åŸºæœ¬çš„æ•°æ®åº“ç®¡ç†çŸ¥è¯†

### ç¯å¢ƒå‡†å¤‡

```bash
# 1. å…‹éš†é¡¹ç›®ï¼ˆå¦‚æœè¿˜æ²¡æœ‰ï¼‰
git clone <repository-url>
cd lawyer-ai-workstation

# 2. å®‰è£…ä¾èµ–
npm install

# 3. å®‰è£…æ•°æ®åº“å·¥å…·
npm install -g @supabase/cli
npm install -g prisma
```

## ğŸ“‹ éƒ¨ç½²æ­¥éª¤

### Step 1: Supabaseé¡¹ç›®è®¾ç½®

```bash
# 1. ç™»å½•Supabase
supabase login

# 2. åˆå§‹åŒ–é¡¹ç›®
supabase init

# 3. å¯åŠ¨æœ¬åœ°å¼€å‘ç¯å¢ƒï¼ˆå¯é€‰ï¼‰
supabase start

# 4. åˆ›å»ºæ–°é¡¹ç›®ï¼ˆåœ¨Supabase Dashboardä¸­ï¼‰
# è®¿é—® https://app.supabase.com
# ç‚¹å‡» "New project"
# è®°å½•é¡¹ç›®URLå’ŒAPIå¯†é’¥
```

### Step 2: ç¯å¢ƒå˜é‡é…ç½®

åˆ›å»º `.env.local` æ–‡ä»¶ï¼š

```bash
# Supabaseé…ç½®
NEXT_PUBLIC_SUPABASE_URL=https://your-project-id.supabase.co
NEXT_PUBLIC_SUPABASE_ANON_KEY=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...
SUPABASE_SERVICE_ROLE_KEY=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...

# æ•°æ®åº“é…ç½®ï¼ˆç”¨äºPrismaï¼‰
DATABASE_URL=postgresql://postgres:[PASSWORD]@db.[PROJECT_ID].supabase.co:5432/postgres?schema=public
SHADOW_DATABASE_URL=postgresql://postgres:[PASSWORD]@db.[PROJECT_ID].supabase.co:5432/postgres?schema=shadow

# JWTé…ç½®
JWT_SECRET=your-super-secret-jwt-key-here
JWT_EXPIRES_IN=24h

# åº”ç”¨é…ç½®
NEXT_PUBLIC_APP_URL=http://localhost:3000
NEXTAUTH_SECRET=your-nextauth-secret-here
NEXTAUTH_URL=http://localhost:3000

# AIæœåŠ¡é…ç½®
OPENROUTER_API_KEY=your-openrouter-api-key
ANTHROPIC_API_KEY=your-anthropic-api-key

# é‚®ä»¶é…ç½®ï¼ˆå¯é€‰ï¼‰
SMTP_HOST=smtp.gmail.com
SMTP_PORT=587
SMTP_USER=your-email@example.com
SMTP_PASS=your-app-password

# æ–‡ä»¶ä¸Šä¼ é…ç½®
MAX_FILE_SIZE=100MB
ALLOWED_FILE_TYPES=pdf,docx,doc,txt,rtf
```

### Step 3: æ•°æ®åº“Schemaéƒ¨ç½²

```bash
# 1. è¿æ¥åˆ°Supabaseé¡¹ç›®
supabase link --project-ref YOUR_PROJECT_ID

# 2. éƒ¨ç½²å®Œæ•´Schema
supabase db push --file database/lawyer-ai-complete-schema.sql

# 3. è¿è¡ŒSupabaseç‰¹å®šè®¾ç½®
supabase db push --file database/supabase-setup.sql

# 4. éªŒè¯éƒ¨ç½²
supabase db diff
```

### Step 4: Prismaè®¾ç½®

```bash
# 1. ç”ŸæˆPrismaå®¢æˆ·ç«¯
npx prisma generate

# 2. åŒæ­¥Schemaï¼ˆå¦‚æœä½¿ç”¨Prismaç®¡ç†Schemaï¼‰
npx prisma db push

# 3. éªŒè¯è¿æ¥
npx prisma db seed
```

### Step 5: åˆå§‹åŒ–æ•°æ®

```bash
# è¿è¡Œæ•°æ®åˆå§‹åŒ–è„šæœ¬
npm run db:seed

# æˆ–æ‰‹åŠ¨æ‰§è¡Œ
psql $DATABASE_URL -f database/seed.sql
```

## ğŸ—ï¸ ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²

### Step 1: ç”Ÿäº§ç¯å¢ƒSupabaseé¡¹ç›®

```bash
# 1. åˆ›å»ºç”Ÿäº§ç¯å¢ƒé¡¹ç›®
# åœ¨Supabase Dashboardä¸­åˆ›å»ºæ–°é¡¹ç›®

# 2. é…ç½®ç”Ÿäº§ç¯å¢ƒå˜é‡
# æ›´æ–° .env.production æ–‡ä»¶

# 3. éƒ¨ç½²åˆ°ç”Ÿäº§æ•°æ®åº“
supabase link --project-ref PROD_PROJECT_ID
supabase db push --file database/lawyer-ai-complete-schema.sql
supabase db push --file database/supabase-setup.sql
```

### Step 2: å®‰å…¨é…ç½®

```sql
-- 1. æ›´æ–°é»˜è®¤å¯†ç 
ALTER USER postgres PASSWORD 'super-secure-production-password';

-- 2. åˆ›å»ºåº”ç”¨ä¸“ç”¨ç”¨æˆ·
CREATE USER lawyerai_app WITH PASSWORD 'secure-app-password';
GRANT CONNECT ON DATABASE postgres TO lawyerai_app;
GRANT USAGE ON SCHEMA public TO lawyerai_app;
GRANT SELECT, INSERT, UPDATE, DELETE ON ALL TABLES IN SCHEMA public TO lawyerai_app;

-- 3. é…ç½®è¿æ¥é™åˆ¶
ALTER USER lawyerai_app CONNECTION LIMIT 20;
```

### Step 3: å¤‡ä»½ç­–ç•¥é…ç½®

```bash
# 1. è®¾ç½®è‡ªåŠ¨å¤‡ä»½
supabase backup create

# 2. é…ç½®å¤‡ä»½ç­–ç•¥
cat > backup-config.json << EOF
{
  "schedule": "0 2 * * *",
  "retention": {
    "daily": 30,
    "weekly": 12,
    "monthly": 12,
    "yearly": 7
  },
  "encryption": true,
  "compression": true
}
EOF
```

## ğŸ”§ é«˜çº§é…ç½®

### æ€§èƒ½ä¼˜åŒ–è®¾ç½®

```sql
-- 1. è¿æ¥æ± é…ç½®
ALTER SYSTEM SET max_connections = 200;
ALTER SYSTEM SET shared_buffers = '256MB';
ALTER SYSTEM SET effective_cache_size = '1GB';
ALTER SYSTEM SET maintenance_work_mem = '64MB';
ALTER SYSTEM SET checkpoint_completion_target = 0.9;
ALTER SYSTEM SET wal_buffers = '16MB';

-- 2. æŸ¥è¯¢ä¼˜åŒ–
ALTER SYSTEM SET random_page_cost = 1.1;
ALTER SYSTEM SET effective_io_concurrency = 200;

-- é‡æ–°åŠ è½½é…ç½®
SELECT pg_reload_conf();
```

### ç›‘æ§é…ç½®

```sql
-- 1. å¯ç”¨æŸ¥è¯¢ç»Ÿè®¡
CREATE EXTENSION IF NOT EXISTS pg_stat_statements;

-- 2. åˆ›å»ºç›‘æ§è§†å›¾
CREATE VIEW system_performance AS
SELECT 
    schemaname,
    tablename,
    seq_scan,
    seq_tup_read,
    idx_scan,
    idx_tup_fetch,
    n_tup_ins,
    n_tup_upd,
    n_tup_del
FROM pg_stat_user_tables
ORDER BY seq_scan DESC;

-- 3. æ…¢æŸ¥è¯¢ç›‘æ§
CREATE VIEW slow_queries AS
SELECT 
    query,
    calls,
    total_time,
    mean_time,
    stddev_time,
    rows
FROM pg_stat_statements
WHERE mean_time > 1000  -- è¶…è¿‡1ç§’çš„æŸ¥è¯¢
ORDER BY mean_time DESC;
```

## ğŸ§ª æµ‹è¯•å’ŒéªŒè¯

### æ•°æ®å®Œæ•´æ€§æµ‹è¯•

```bash
# 1. è¿è¡Œå®Œæ•´æ€§æ£€æŸ¥
npm run test:db-integrity

# 2. éªŒè¯çº¦æŸ
npm run test:db-constraints

# 3. æ€§èƒ½æµ‹è¯•
npm run test:db-performance
```

### åŠŸèƒ½æµ‹è¯•è„šæœ¬

```typescript
// test/database/integration.test.ts
import { LawyerAIDatabase } from '../../lib/database';

describe('Database Integration Tests', () => {
  let db: LawyerAIDatabase;
  
  beforeAll(async () => {
    db = createLawyerAIDatabase(
      process.env.TEST_SUPABASE_URL!,
      process.env.TEST_SUPABASE_KEY!
    );
  });

  test('should create law firm and user', async () => {
    const firmResult = await db.createLawFirm({
      name: 'Test Law Firm',
      email: 'test@example.com',
      jurisdiction: 'CA'
    });
    
    expect(firmResult.success).toBe(true);
    expect(firmResult.data).toBeDefined();
    
    const userResult = await db.createUser({
      law_firm_id: firmResult.data!.id,
      email: 'lawyer@example.com',
      full_name: 'Test Lawyer',
      role: 'attorney'
    });
    
    expect(userResult.success).toBe(true);
    expect(userResult.data?.role).toBe('attorney');
  });

  test('should enforce RLS policies', async () => {
    // æµ‹è¯•å¤šç§Ÿæˆ·æ•°æ®éš”ç¦»
    await db.setCurrentUser('user1');
    const cases1 = await db.getCases();
    
    await db.setCurrentUser('user2');
    const cases2 = await db.getCases();
    
    // ä¸åŒç”¨æˆ·åº”è¯¥çœ‹åˆ°ä¸åŒçš„æ•°æ®
    expect(cases1.data?.items).not.toEqual(cases2.data?.items);
  });
});
```

## ğŸ“Š ç›‘æ§å’Œè¿ç»´

### æ—¥å¸¸ç›‘æ§æ£€æŸ¥é¡¹

```sql
-- 1. æ•°æ®åº“å¥åº·æ£€æŸ¥
SELECT 
    'Database Size' as metric,
    pg_size_pretty(pg_database_size(current_database())) as value
UNION ALL
SELECT 
    'Active Connections',
    COUNT(*)::text
FROM pg_stat_activity
WHERE state = 'active'
UNION ALL
SELECT 
    'Cache Hit Ratio',
    ROUND(100 * sum(heap_blks_hit) / (sum(heap_blks_hit) + sum(heap_blks_read)), 2)::text || '%'
FROM pg_statio_user_tables;

-- 2. è¡¨å¤§å°ç›‘æ§
SELECT 
    schemaname,
    tablename,
    pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) as size,
    pg_total_relation_size(schemaname||'.'||tablename) as size_bytes
FROM pg_tables
WHERE schemaname = 'public'
ORDER BY size_bytes DESC;

-- 3. ç´¢å¼•ä½¿ç”¨æƒ…å†µ
SELECT 
    schemaname,
    tablename,
    indexname,
    idx_scan,
    idx_tup_read,
    idx_tup_fetch
FROM pg_stat_user_indexes
WHERE idx_scan = 0  -- æœªä½¿ç”¨çš„ç´¢å¼•
ORDER BY pg_relation_size(indexrelid) DESC;
```

### è‡ªåŠ¨åŒ–ç»´æŠ¤è„šæœ¬

```bash
#!/bin/bash
# maintenance.sh - æ•°æ®åº“ç»´æŠ¤è„šæœ¬

set -e

# é…ç½®
DATABASE_URL="${DATABASE_URL}"
BACKUP_DIR="/backups"
LOG_FILE="/var/log/lawyerai-maintenance.log"

echo "[$(date)] Starting database maintenance..." >> $LOG_FILE

# 1. æ•°æ®åº“å¤‡ä»½
echo "[$(date)] Creating backup..." >> $LOG_FILE
pg_dump $DATABASE_URL | gzip > "$BACKUP_DIR/lawyerai-$(date +%Y%m%d).sql.gz"

# 2. æ¸…ç†è¿‡æœŸå®¡è®¡æ—¥å¿—
echo "[$(date)] Cleaning up audit logs..." >> $LOG_FILE
psql $DATABASE_URL -c "SELECT cleanup_expired_audit_logs();"

# 3. æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
echo "[$(date)] Updating statistics..." >> $LOG_FILE
psql $DATABASE_URL -c "ANALYZE;"

# 4. é‡æ–°ç´¢å¼•ï¼ˆå¿…è¦æ—¶ï¼‰
echo "[$(date)] Reindexing..." >> $LOG_FILE
psql $DATABASE_URL -c "REINDEX DATABASE lawyerai;"

# 5. æ£€æŸ¥æ•°æ®å®Œæ•´æ€§
echo "[$(date)] Checking data integrity..." >> $LOG_FILE
psql $DATABASE_URL -c "SELECT run_compliance_checks();"

echo "[$(date)] Maintenance completed successfully!" >> $LOG_FILE
```

### å‘Šè­¦è®¾ç½®

```yaml
# alerts.yml - ç›‘æ§å‘Šè­¦é…ç½®
alerts:
  - name: high_connection_usage
    condition: "active_connections > 80% of max_connections"
    severity: warning
    action: notify_admin
    
  - name: slow_queries_detected
    condition: "queries with exec_time > 5s"
    severity: critical
    action: [notify_admin, log_query]
    
  - name: disk_space_low
    condition: "database_size > 80% of allocated space"
    severity: warning
    action: [notify_admin, suggest_cleanup]
    
  - name: backup_failed
    condition: "last_backup_age > 25 hours"
    severity: critical
    action: [notify_admin, retry_backup]
```

## ğŸ”§ æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜è§£å†³æ–¹æ¡ˆ

#### 1. è¿æ¥é—®é¢˜
```bash
# æ£€æŸ¥è¿æ¥çŠ¶æ€
psql $DATABASE_URL -c "SELECT version();"

# æ£€æŸ¥è¿æ¥æ•°
psql $DATABASE_URL -c "SELECT COUNT(*) FROM pg_stat_activity;"

# æ€æ­»ç©ºé—²è¿æ¥
psql $DATABASE_URL -c "
SELECT pg_terminate_backend(pid)
FROM pg_stat_activity
WHERE state = 'idle' AND state_change < NOW() - INTERVAL '1 hour';
"
```

#### 2. æ€§èƒ½é—®é¢˜
```sql
-- æŸ¥æ‰¾æ…¢æŸ¥è¯¢
SELECT query, calls, total_time, mean_time
FROM pg_stat_statements
ORDER BY mean_time DESC
LIMIT 10;

-- æŸ¥æ‰¾ç¼ºå¤±ç´¢å¼•
SELECT 
    schemaname,
    tablename,
    seq_scan,
    seq_tup_read,
    idx_scan,
    seq_tup_read / seq_scan as avg_seq_read
FROM pg_stat_user_tables
WHERE seq_scan > 0
ORDER BY seq_tup_read DESC;
```

#### 3. å­˜å‚¨ç©ºé—´é—®é¢˜
```sql
-- æ¸…ç†ä¸´æ—¶æ–‡ä»¶
SELECT pg_ls_tmpdir();

-- æŸ¥æ‰¾å¤§è¡¨
SELECT 
    schemaname,
    tablename,
    pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) as size
FROM pg_tables
WHERE schemaname = 'public'
ORDER BY pg_total_relation_size(schemaname||'.'||tablename) DESC;

-- æ¸…ç†è¿‡æœŸæ•°æ®
SELECT cleanup_expired_audit_logs();
```

## ğŸ“ˆ æ‰©å±•å’Œå‡çº§

### æ•°æ®åº“ç‰ˆæœ¬å‡çº§

```bash
# 1. å¤‡ä»½å½“å‰æ•°æ®
pg_dump $DATABASE_URL > backup-before-upgrade.sql

# 2. æµ‹è¯•å‡çº§ï¼ˆåœ¨æµ‹è¯•ç¯å¢ƒï¼‰
supabase db upgrade --dry-run

# 3. æ‰§è¡Œå‡çº§
supabase db upgrade

# 4. éªŒè¯å‡çº§
npm run test:db-integrity
```

### Schemaå˜æ›´ç®¡ç†

```sql
-- 1. åˆ›å»ºè¿ç§»è„šæœ¬
-- migrations/001_add_new_feature.sql
BEGIN;

-- æ·»åŠ æ–°åˆ—
ALTER TABLE cases ADD COLUMN IF NOT EXISTS priority_score INTEGER DEFAULT 0;

-- åˆ›å»ºç´¢å¼•
CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_cases_priority_score ON cases(priority_score);

-- æ›´æ–°ç°æœ‰æ•°æ®
UPDATE cases SET priority_score = 
  CASE priority
    WHEN 'critical' THEN 4
    WHEN 'high' THEN 3
    WHEN 'medium' THEN 2
    WHEN 'low' THEN 1
    ELSE 0
  END;

-- è®°å½•è¿ç§»
INSERT INTO schema_migrations (version, applied_at) VALUES ('001', NOW());

COMMIT;
```

### è´Ÿè½½æµ‹è¯•

```javascript
// loadtest.js
const { LawyerAIDatabase } = require('./lib/database');

const runLoadTest = async () => {
  const db = createLawyerAIDatabase(
    process.env.DATABASE_URL,
    process.env.SUPABASE_KEY
  );
  
  console.log('Starting load test...');
  
  const promises = [];
  for (let i = 0; i < 100; i++) {
    promises.push(
      db.getCases({ limit: 10 }).then(result => {
        if (!result.success) {
          console.error(`Request ${i} failed:`, result.error);
        }
        return result.success;
      })
    );
  }
  
  const results = await Promise.all(promises);
  const successCount = results.filter(Boolean).length;
  
  console.log(`Load test completed: ${successCount}/100 requests successful`);
};

runLoadTest();
```

## ğŸ¯ æœ€ä½³å®è·µæ€»ç»“

### å¼€å‘æœ€ä½³å®è·µ

1. **å§‹ç»ˆä½¿ç”¨äº‹åŠ¡**
   ```typescript
   const result = await db.executeTransaction([
     (client) => client.from('cases').insert(caseData),
     (client) => client.from('case_participants').insert(participantData)
   ]);
   ```

2. **å®æ–½é€‚å½“çš„é”™è¯¯å¤„ç†**
   ```typescript
   try {
     const result = await db.createCase(caseData);
     if (!result.success) {
       throw new Error(result.error);
     }
     return result.data;
   } catch (error) {
     logger.error('Case creation failed:', error);
     throw error;
   }
   ```

3. **ä½¿ç”¨ç±»å‹å®‰å…¨çš„æŸ¥è¯¢**
   ```typescript
   const cases = await db.getCases({
     status: CaseStatus.ACTIVE,
     priority: CasePriority.HIGH,
     limit: 20
   });
   ```

### å®‰å…¨æœ€ä½³å®è·µ

1. **æ€»æ˜¯éªŒè¯ç”¨æˆ·æƒé™**
2. **ä½¿ç”¨å‚æ•°åŒ–æŸ¥è¯¢é˜²æ­¢SQLæ³¨å…¥**
3. **åŠ å¯†æ•æ„Ÿæ•°æ®**
4. **å®šæœŸå®¡è®¡è®¿é—®æ—¥å¿—**
5. **å®æ–½æœ€å°æƒé™åŸåˆ™**

### æ€§èƒ½æœ€ä½³å®è·µ

1. **åˆç†ä½¿ç”¨ç´¢å¼•**
2. **é¿å…N+1æŸ¥è¯¢é—®é¢˜**
3. **ä½¿ç”¨è¿æ¥æ± **
4. **å®æ–½æŸ¥è¯¢ç¼“å­˜**
5. **å®šæœŸåˆ†ææ…¢æŸ¥è¯¢**

é€šè¿‡éµå¾ªè¿™ä¸ªéƒ¨ç½²æŒ‡å—ï¼Œæ‚¨å¯ä»¥å®‰å…¨ã€é«˜æ•ˆåœ°éƒ¨ç½²å’Œè¿ç»´å¾‹å¸ˆAIå·¥ä½œå°çš„æ•°æ®åº“ç³»ç»Ÿã€‚è®°ä½å®šæœŸå¤‡ä»½ã€ç›‘æ§æ€§èƒ½æŒ‡æ ‡ï¼Œå¹¶ä¿æŒç³»ç»Ÿæ›´æ–°ä»¥ç¡®ä¿æœ€ä½³çš„å®‰å…¨æ€§å’Œæ€§èƒ½ã€‚